p8105_hw2_mkr2158
================
Matariya Rattanapan
2025-09-30

Loading libraries

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

Cleaning up the pols-month dataset.

``` r
pols_df = 
  read_csv("fivethirtyeight_datasets/pols-month.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    month = recode(month, "01" = "January", "02" = "February", "03" = "March", "04" = "April", "05" = "May", "06" = "June", "07"= "July", "08" = "August", "09" = "September", "10" = "October", "11" = "November", "12" = "December"),
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )) |> 
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Cleaning up the snp dataset.

``` r
snp_df =
  read_csv("fivethirtyeight_datasets/snp.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    month = recode(month,"1" = "January", "2" = "February", "3" = "March", "4" = "April", "5" = "May", "6" = "June", "7"= "July", "8" = "August", "9" = "September", "10" = "October", "11" = "November", "12" = "December"),
    year = case_when(
      as.numeric(year) >= 50 ~ paste0("19", year),
      as.numeric(year) < 50 ~ paste0("20", year)
    )
  ) |> 
  arrange(year, month) |> 
  select(year, month, close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Cleaning up unemployment dataset.

``` r
unemploy_df =
  read_csv("fivethirtyeight_datasets/unemployment.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment_pct"
  ) |> 
  mutate(
    month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December"),
    year = as.character(year)
  ) |> 
  arrange(year, month) |> 
  select(year, month, unemployment_pct)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merging the cleaned up pols-month, snp, and unemployment datasets.

``` r
merged_df =
  left_join(pols_df, snp_df, by = c("year", "month"))

finalmerge_df =
  left_join(merged_df, unemploy_df, by = c("year", "month"))
```

Using the `knitr::kable` function to check to see our final merged data
was created successfully.

``` r
knitr::kable(head(finalmerge_df, 5))
```

| year | month | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem | president | close | unemployment_pct |
|:---|:---|---:|---:|---:|---:|---:|---:|:---|---:|---:|
| 1947 | January | 23 | 51 | 253 | 23 | 45 | 198 | dem | NA | NA |
| 1947 | February | 23 | 51 | 253 | 23 | 45 | 198 | dem | NA | NA |
| 1947 | March | 23 | 51 | 253 | 23 | 45 | 198 | dem | NA | NA |
| 1947 | April | 23 | 51 | 253 | 23 | 45 | 198 | dem | NA | NA |
| 1947 | May | 23 | 51 | 253 | 23 | 45 | 198 | dem | NA | NA |

The dataset from `pols_df` was cleaned up and contains 822 observations
and 9 variables. It contains important variables describing the number
of democratic or republican politicians at the associated years and
months, including the presidents, governors, senators, and
representatives. The dataset from `snp_df` was cleaned up and contains
787 observations and 3 variables. It contains the closing value of the
Standard & Poor’s (S&P) stock market index at the associated years and
months. The dataset from `unemployment` was cleaned up and contained 816
observations and 3 variables. It contains the percentage of unemployment
at the associated years and months, respectively. Our final dataset
`finalmerge_df` contains 822 observations and 11 variables. The range of
year for our final merged dataset is from January 1947 to June 2015. Key
variables in our final dataset include the `year`, `month`, `president`,
`close`, and `unemployment_pct`.

## Problem 2

Read and clean the Mr. Trash Wheel sheet

``` r
mrtrash_df =
  read_excel("Trash_Wheel_Collection_Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N709",na = c("NA", ".", ""), skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    wheel = "mr"
  ) |> 
  rename(weight = weight_tons, volume = volume_cubic_yards, cigarette = cigarette_butts)
```

Read and clean Professor Trash Wheel sheet

``` r
proftrash_df =
  read_excel("Trash_Wheel_Collection_Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M709",na = c("NA", ".", ""), skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    wheel = "prof",
    year = as.character(year)
  ) |> 
  rename(weight = weight_tons, volume = volume_cubic_yards, cigarette = cigarette_butts)
```

Read and clean Gwynnda Trash Wheel sheet

``` r
gwynnda_df =
  read_excel("Trash_Wheel_Collection_Data.xlsx", sheet = "Gwynns Falls Trash Wheel", range = "A2:L709",na = c("NA", ".", ""), skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    wheel = "gwynns",
    year = as.character(year)
  ) |> 
  rename(weight = weight_tons, volume = volume_cubic_yards, cigarette = cigarette_butts)
```

Merging Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel
into one dataset

``` r
trashfinal_df =
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df)
```

The final dataset after cleaning up and merging the data sets together
contains 1188 observations and 15 variables. Key variables include
`weight` of the trash collected in tons, `volume` of trash collected in
cubic yards, and types of litter such as `plastic bottles`,
`polystyrene`, `cigarette buds`, `glass bottles`, `plastic bags`,
`sports balls`, and `wrappers`.

Calculating the total weight of trash collected by Professor Trash Wheel

``` r
total_prof_weight = trashfinal_df |> 
  filter(wheel=="prof") |> 
  summarise(total_weight=sum(weight, na.rm = TRUE))
```

The total weight of trash collected by Professor Trash Wheel is 282.26
tons.

Calculating the total number of cigarette butts collected by Gwynnda in
June of 2022.

``` r
total_gwynn_cig = trashfinal_df |> 
  filter(wheel == "gwynns", month == "June", year == 2022) |> 
  summarise(total_cigs=sum(cigarette, na.rm = TRUE))
```

The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}.

## Problem 3

Read and cleaning the zillow datasets.

``` r
zipcodes_df = 
  read_csv("zillow_data/zip_codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  mutate(
    county = recode(county, "New York" = "Manhattan", "Kings" = "Brooklyn", "Richmond" = "Staten Island", "Queens" = "Queens", "Bronx" = "Bronx")
  ) |> 
  rename(borough = county)
```

Read and clean zori dataset.

``` r
zori_df =
  read_csv("zillow_data/zori_nyc.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = x2015_01_31:x2024_08_31,
    names_to = "date",
    values_to = "rent"
    ) |> 
  mutate(
    date = str_remove(date, "x"),
    county_name = recode(county_name, "New York County" = "Manhattan", "Kings County" = "Brooklyn", "Richmond County" = "Staten Island", "Queens County" = "Queens", "Bronx County" = "Bronx")
  ) |> 
    rename(
      borough = county_name,
      zip_code = region_name) |> 
    select(-region_type, -state_name)
```

Merging `zipcode` and `zori` dataset.

``` r
zillowmerge_df = 
  left_join(zori_df, zipcodes_df, by = c("zip_code", "borough")) |> 
  arrange(rent) |> 
  relocate(borough, neighborhood, zip_code, rent, date)
```

The resulting tidy dataset `zillowmerge_df` contains 17284 observations
and contains 14 variables. Key variables include borough (Manhattan,
Brooklyn, Queens, Bronx, and Staten Island), neighborhood, zip code,
rent, and date. There are a total of 149 unique zip codes. There are a
total of 42 unique neighborhoods.

Figuring out which zip codes appear in `zip_code` dataset but NOT in
`zori` dataset.

``` r
zip_zipcode_df =
  unique(pull(zipcodes_df, zip_code))

zip_zori_df =
  unique(pull(zori_df, zip_code))
```

There are 171 zipcodes that appear in the `zip code` dataset but is not
in the `zori` (Zillow Rental Price) dataset. These zips codes might have
been excluded from the Zillow dataset for a variety of reasons. For one,
Zillow is a real estate platform and may not include zip codes for areas
where there is not much real estate (i.e. unhabitated areas). Another
reason could be the zip codes cover non-residential usage areas such as
commercial or governmental use. Within these areas, there may be less
homes available for Zillow to feature for rent or for sale. Another
possible reason is some zip codes are used specifically for Post Office
boxes or PO boxes. These would evidently not be within Zillow’s database
for homes for rent/sale.

Comparing rental prices in January 2021 to prices in January 2020

``` r
jan_rent_change =
  zillowmerge_df |> 
  filter(date %in% c("2020_01_31", "2021_01_31")) |> 
  group_by(zip_code, borough, neighborhood) |> 
  summarise(
    jan_2020 = rent[date == "2020_01_31"],
    jan_2021 = rent[date == "2021_01_31"]
  ) |> 
  mutate(
    rent_change = jan_2021 - jan_2020
  ) |> 
  arrange(rent_change) |> 
  select(borough, neighborhood, zip_code, jan_2020, jan_2021, rent_change) |> 
  drop_na(rent_change)
```

    ## `summarise()` has grouped output by 'zip_code', 'borough'. You can override
    ## using the `.groups` argument.

``` r
  knitr::kable(head(jan_rent_change,10))
```

| borough | neighborhood | zip_code | jan_2020 | jan_2021 | rent_change |
|:---|:---|---:|---:|---:|---:|
| Manhattan | Lower Manhattan | 10007 | 6334.211 | 5421.614 | -912.5966 |
| Manhattan | NA | 10069 | 4623.042 | 3874.918 | -748.1245 |
| Manhattan | Lower East Side | 10009 | 3406.442 | 2692.187 | -714.2550 |
| Manhattan | Gramercy Park and Murray Hill | 10016 | 3731.135 | 3019.431 | -711.7045 |
| Manhattan | Chelsea and Clinton | 10001 | 4108.098 | 3397.648 | -710.4499 |
| Manhattan | Lower East Side | 10002 | 3645.416 | 2935.113 | -710.3028 |
| Manhattan | Lower Manhattan | 10004 | 3149.658 | 2443.697 | -705.9608 |
| Manhattan | Lower Manhattan | 10038 | 3573.201 | 2875.616 | -697.5853 |
| Manhattan | Greenwich Village and Soho | 10012 | 3628.566 | 2942.344 | -686.2218 |
| Manhattan | Gramercy Park and Murray Hill | 10010 | 3697.284 | 3012.353 | -684.9304 |

Based off our table, we can see that Lower Manhattan, Manhattan had the
largest drop in rental price, from January 2020 to January 2021 from
6334.21 USD to 5421.61 USD, a -912.6 USD difference.
